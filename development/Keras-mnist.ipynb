{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, Activation, Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "\n",
    "x_train = x_train.tolist()\n",
    "y_train = y_train.tolist()\n",
    "\n",
    "x_1 = cv2.imread(\"img-07.png\", 0) / 255.0\n",
    "x_6 = cv2.imread(\"img-85.png\", 0) / 255.0\n",
    "\n",
    "for i in range(700):\n",
    "    x_train.append(np.zeros((28, 28), dtype=np.float64))\n",
    "    y_train.append(0)\n",
    "    x_train.append(np.array(x_1))\n",
    "    y_train.append(1)\n",
    "    x_train.append(np.array(x_6))\n",
    "    y_train.append(6)\n",
    "\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.333)\n",
    "\n",
    "epochs = 20\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x+epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 327,242\n",
      "Trainable params: 326,410\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,kernel_size=3,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "647/647 [==============================] - 18s 24ms/step - loss: 0.8163 - accuracy: 0.7440 - val_loss: 0.0957 - val_accuracy: 0.9703\n",
      "Epoch 2/20\n",
      "647/647 [==============================] - 15s 23ms/step - loss: 0.2125 - accuracy: 0.9351 - val_loss: 0.0686 - val_accuracy: 0.9794\n",
      "Epoch 3/20\n",
      "647/647 [==============================] - 15s 24ms/step - loss: 0.1408 - accuracy: 0.9580 - val_loss: 0.0788 - val_accuracy: 0.9696\n",
      "Epoch 4/20\n",
      "647/647 [==============================] - 15s 24ms/step - loss: 0.1089 - accuracy: 0.9677 - val_loss: 0.0660 - val_accuracy: 0.9808\n",
      "Epoch 5/20\n",
      "647/647 [==============================] - 15s 24ms/step - loss: 0.0905 - accuracy: 0.9726 - val_loss: 0.0352 - val_accuracy: 0.9899\n",
      "Epoch 6/20\n",
      "647/647 [==============================] - 15s 23ms/step - loss: 0.0733 - accuracy: 0.9778 - val_loss: 0.0427 - val_accuracy: 0.9870\n",
      "Epoch 7/20\n",
      "647/647 [==============================] - 16s 24ms/step - loss: 0.0699 - accuracy: 0.9794 - val_loss: 0.0339 - val_accuracy: 0.9898\n",
      "Epoch 8/20\n",
      "647/647 [==============================] - 15s 24ms/step - loss: 0.0626 - accuracy: 0.9814 - val_loss: 0.0313 - val_accuracy: 0.9907\n",
      "Epoch 9/20\n",
      "647/647 [==============================] - 15s 24ms/step - loss: 0.0597 - accuracy: 0.9822 - val_loss: 0.0261 - val_accuracy: 0.9924\n",
      "Epoch 10/20\n",
      "647/647 [==============================] - 15s 24ms/step - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.0256 - val_accuracy: 0.9927\n",
      "Epoch 11/20\n",
      "647/647 [==============================] - 15s 24ms/step - loss: 0.0450 - accuracy: 0.9866 - val_loss: 0.0223 - val_accuracy: 0.9932\n",
      "Epoch 12/20\n",
      "647/647 [==============================] - 16s 25ms/step - loss: 0.0468 - accuracy: 0.9862 - val_loss: 0.0202 - val_accuracy: 0.9941\n",
      "Epoch 13/20\n",
      "647/647 [==============================] - 16s 25ms/step - loss: 0.0423 - accuracy: 0.9875 - val_loss: 0.0250 - val_accuracy: 0.9928\n",
      "Epoch 14/20\n",
      "647/647 [==============================] - 16s 25ms/step - loss: 0.0420 - accuracy: 0.9873 - val_loss: 0.0208 - val_accuracy: 0.9929\n",
      "Epoch 15/20\n",
      "647/647 [==============================] - 16s 24ms/step - loss: 0.0379 - accuracy: 0.9888 - val_loss: 0.0216 - val_accuracy: 0.9931\n",
      "Epoch 16/20\n",
      "647/647 [==============================] - 17s 26ms/step - loss: 0.0349 - accuracy: 0.9894 - val_loss: 0.0193 - val_accuracy: 0.9941\n",
      "Epoch 17/20\n",
      "647/647 [==============================] - 18s 27ms/step - loss: 0.0323 - accuracy: 0.9913 - val_loss: 0.0216 - val_accuracy: 0.9939\n",
      "Epoch 18/20\n",
      "647/647 [==============================] - 17s 27ms/step - loss: 0.0336 - accuracy: 0.9900 - val_loss: 0.0202 - val_accuracy: 0.9942\n",
      "Epoch 19/20\n",
      "647/647 [==============================] - 16s 24ms/step - loss: 0.0333 - accuracy: 0.9903 - val_loss: 0.0192 - val_accuracy: 0.9941\n",
      "Epoch 20/20\n",
      "647/647 [==============================] - 16s 24ms/step - loss: 0.0326 - accuracy: 0.9904 - val_loss: 0.0193 - val_accuracy: 0.9944\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=5,  \n",
    "        zoom_range = 0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=64), \n",
    "    epochs = epochs, steps_per_epoch = x_train.shape[0]//64,\n",
    "    validation_data = (x_val, y_val), callbacks=[annealer], verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0145 - accuracy: 0.9953\n",
      "(10000,) (10000,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       980\n",
      "           1       0.99      1.00      1.00      1135\n",
      "           2       1.00      1.00      1.00      1032\n",
      "           3       0.99      1.00      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       1.00      0.99      0.99       892\n",
      "           6       1.00      0.99      1.00       958\n",
      "           7       1.00      0.99      0.99      1028\n",
      "           8       1.00      1.00      1.00       974\n",
      "           9       0.99      0.99      0.99      1009\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(y_pred.shape, y_test.shape)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../Keras-Models/CNN+BN+DA-5/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../Keras-Models/CNN+BN+DA-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "model = load_model(\"digit_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45674202 0.5944998  0.4800058  0.45394    0.5175149  0.4436968\n",
      "  0.4751583  0.51630557 0.5160351  0.42816165]]\n",
      "[[7.4413083e-06 2.1672030e-03 5.7088761e-07 9.8061025e-01 2.2372857e-05\n",
      "  1.0000000e+00 4.5162495e-03 1.3231435e-04 9.3374252e-03 1.8740301e-01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = random.randint(0, 500)\n",
    "x = np.zeros((28, 28))+255\n",
    "cv2.imshow(\"img\", x)\n",
    "cv2.imshow(\"test\", x_test[i].reshape(28, 28))\n",
    "\n",
    "\n",
    "x = x.reshape(-1, 28, 28, 1)\n",
    "x = tf.keras.utils.normalize(x, axis=1)\n",
    "# print(x.shape)\n",
    "# x = x.reshape(-1, 28, 28, 1)\n",
    "pred = model.predict(x)\n",
    "print(pred)\n",
    "\n",
    "# model.evaluate(x_test, y_test)\n",
    "\n",
    "y_pred = model.predict(x_test[i].reshape(-1, 28, 28, 1))\n",
    "print(y_pred)\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"data.npy\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"test\", data[3])\n",
    "\n",
    "# model.predict()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img-26.png\", 0)\n",
    "x = img.reshape(-1, 28, 28, 1)\n",
    "x = x/255.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
